{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern,RationalQuadratic\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "\n",
    "import time\n",
    "import random\n",
    "from utils import data_handler, plotter\n",
    "\n",
    "#handle warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(y_pred,y_true):\n",
    "    '''Evaluate the performance of model through 3 metrics: r^2, mse, pear\n",
    "       \n",
    "       Inputs:\n",
    "           y_pred      - for testing\n",
    "           y_true      - ground true for X_test\n",
    "           \n",
    "           \n",
    "       Outputs:\n",
    "           [r^2, mse,pear, pear_p_value] - np.array() \n",
    "               \n",
    "    '''\n",
    "    \n",
    "    r2 = metrics.r2_score(y_true,y_pred)   \n",
    "    mse = metrics.mean_squared_error(y_true,y_pred)\n",
    "    [pear,p_value] = pearsonr(y_true,y_pred)\n",
    "    \n",
    "\n",
    "    return np.array([r2,mse,pear,p_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df,Y_df = data_handler.load_XY(1)\n",
    "X = X_df.as_matrix()\n",
    "Y = Y_df.as_matrix()/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalization - Nested Cross Validatoin\n",
    "1. Outer CV: 10-fold cross validation (10 repetitions)\n",
    "2. Inner CV: 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup\n",
    "verbose=False\n",
    "n_jobs = 4\n",
    "save_csv = True\n",
    "\n",
    "\n",
    "# cross validation setup\n",
    "Ntrials = 10\n",
    "outter_nsplit = 10\n",
    "inner_nsplits = 10\n",
    "\n",
    "print('start  ',str(Ntrials),' trials...')\n",
    "tot_count = Ntrials * outter_nsplit\n",
    "\n",
    "# Results store\n",
    "svr_mat = np.zeros((tot_count,4))\n",
    "xgb_mat = np.zeros((tot_count,4))\n",
    "mlp_mat = np.zeros((tot_count,4))\n",
    "gpr_mat = np.zeros((tot_count,4))\n",
    "\n",
    "for i in range(Ntrials):\n",
    "    init_time = time.time()\n",
    "    train_index = []  \n",
    "    test_index = []  \n",
    "\n",
    "    outer_cv = KFold(n_splits=outter_nsplit, shuffle=True, random_state=i+9)\n",
    "    for train_ind,test_ind in outer_cv.split(Y):\n",
    "        train_index.append(train_ind.tolist())\n",
    "        test_index.append(test_ind.tolist())\n",
    "\n",
    "\n",
    "    for j in range(outter_nsplit):#outter_nsplit\n",
    "        count = i * outter_nsplit + j\n",
    "        print(str(count), \"  / \",str(tot_count))\n",
    "        X_train = X[train_index[j]]\n",
    "        Y_train = Y[train_index[j]]\n",
    "\n",
    "        X_test = X[test_index[j]]\n",
    "        Y_test = Y[test_index[j]]\n",
    "\n",
    "        inner_cv = KFold(n_splits=inner_nsplits, shuffle=False, random_state=j)  \n",
    "\n",
    "\n",
    "        # gpr\n",
    "        kernel =  Matern(length_scale=1.0, length_scale_bounds=(1e-05, 100000.0), nu=1.5) +\\\n",
    "                RationalQuadratic(length_scale=1.0, alpha=1.0, length_scale_bounds=(1e-05, 100000.0), alpha_bounds=(1e-05, 100000.0)) \n",
    "        gpr_reg = Pipeline([            \n",
    "                ('sc', StandardScaler()), \n",
    "                ('reg',  GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10))\n",
    "                ])\n",
    "\n",
    "        gpr_reg.fit(X_train, Y_train)\n",
    "        y_pred = gpr_reg.predict(X_test)\n",
    "        gpr_mat[count] = test(Y_test,y_pred)\n",
    "\n",
    "        # SVR - rbf\n",
    "        svr_rbf = Pipeline([            \n",
    "                ('sc', StandardScaler()), \n",
    "                ('reg',  SVR())\n",
    "                ])\n",
    "        tuned_parameters = dict(reg__kernel=['rbf'],\n",
    "                                reg__tol= [1e-3,1e-2,1e-1],\n",
    "                                reg__C=[0.9,1,1.1],\n",
    "                                reg__epsilon=[0,0.1,0.2],\n",
    "                                reg__gamma=[1e-3,1e-2,1e-1,1/6]\n",
    "                              )\n",
    "        svr_cv = GridSearchCV(svr_rbf,tuned_parameters, cv=inner_cv, scoring='r2',verbose=verbose,n_jobs=n_jobs)\n",
    "        svr_cv.fit(X_train, Y_train)\n",
    "        y_pred = svr_cv.predict(X_test)\n",
    "        svr_mat[count] = test(Y_test,y_pred)\n",
    "\n",
    "        # GradientBoost\n",
    "        tuned_parameters = dict(objective=[\"reg:linear\"],\n",
    "                            learning_rate=[0.01],\n",
    "                            n_estimators=[300,500,700], #100,,300,400,500\n",
    "                            colsample_bylevel = [0.5,0.7,0.9],\n",
    "                          gamma=[0,0.2], #0,0.1,0.2,0.3,0.4\n",
    "                          max_depth =[3,7,11], # [3,7,11]]\n",
    "                          reg_lambda = [0.1,1,10], #[0.1,1,10]\n",
    "                         # reg_alpha = [1],\n",
    "                           subsample=[0.4,0.7,1])\n",
    "\n",
    "        xgb_reg = xgb.XGBRegressor(min_child_weight=1,**{'tree_method':'exact'},\n",
    "                                 silent=True,n_jobs=4,random_state=3,seed=3);\n",
    "\n",
    "        xgb_cv = GridSearchCV(xgb_reg,tuned_parameters, cv=inner_cv,scoring='r2',verbose=verbose,n_jobs=4)\n",
    "        xgb_cv.fit(X_train, Y_train)\n",
    "        y_pred = xgb_cv.predict(X_test)\n",
    "        xgb_mat[count] = test(Y_test,y_pred)\n",
    "\n",
    "\n",
    "        # MLP\n",
    "        mlp_clf = Pipeline([            \n",
    "                ('sc', StandardScaler()), \n",
    "                ('reg',  MLPRegressor())\n",
    "                ])\n",
    "        tuned_parameters = dict(reg__hidden_layer_sizes=[[5],[10],[20],[5,5],[10,10],[20,20],[5,5,5],[10,10,10],[20,20,20]],\n",
    "                          reg__alpha=[1e-4,1e-3, 1e-2, 1e-1,1], #L2 penalty (regularization term) parameter.\n",
    "                          reg__early_stopping=[True],\n",
    "                         reg__solver= ['lbfgs'])\n",
    "        mlp_cv = GridSearchCV(mlp_clf, tuned_parameters, cv=inner_cv,scoring='r2',verbose=verbose,n_jobs=n_jobs)\n",
    "        mlp_cv.fit(X_train, Y_train)\n",
    "        y_pred = mlp_cv.predict(X_test)\n",
    "        mlp_mat[count] = test(Y_test,y_pred)\n",
    "\n",
    "        if verbose:\n",
    "            print('svr - ',svr_mat[count])\n",
    "            print('gpr - ',gpr_mat[count])\n",
    "            print('mlp - ',mlp_mat[count])\n",
    "            print('xgb -',xgb_mat[count])\n",
    "    print((time.time()-init_time)/60, ' min')\n",
    "\n",
    "\n",
    "mlp_results = pd.DataFrame(data =mlp_mat, columns=['r2','mse','pear','pear_p_val'])  \n",
    "gpr_results = pd.DataFrame(data =gpr_mat, columns=['r2','mse','pear','pear_p_val'])         \n",
    "xgb_results = pd.DataFrame(data =xgb_mat, columns=['r2','mse','pear','pear_p_val'])        \n",
    "svr_results = pd.DataFrame(data =svr_mat, columns=['r2','mse','pear','pear_p_val'])   \n",
    "\n",
    "if(save_csv):\n",
    "    data_handler.save_csv(gpr_results, title='[model_selection_reg]gpr_results')\n",
    "    data_handler.save_csv(mlp_results, title='[model_selection_reg]mlp_results')\n",
    "    data_handler.save_csv(xgb_results, title='[model_selection_reg]xgb_results')\n",
    "    data_handler.save_csv(svr_results, title='[model_selection_reg]svr_results')\n",
    "\n",
    "print('end ',str(Ntrials),' trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Best Model\n",
    "1. Comparing 4 performance metrics \n",
    "    - visualizing by boxplots\n",
    "2. Bayesian correlated t-test\n",
    "    - to verify recognizable difference between the best model versus other three candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "\n",
    "print('->>>XGBoost_mean : \\n',xgb_results.mean(axis=0), '\\n  std = \\n', xgb_results.std(axis=0))\n",
    "print('->>>SVR_mean : \\n',svr_results.mean(axis=0),' \\n std =\\n',svr_results.std(axis=0) )\n",
    "print('->>>MLP_mean : \\n',mlp_results.mean(axis=0), ' \\n std =\\n',mlp_results.std(axis=0))\n",
    "print('->>>GPR_mean : \\n',gpr_results.mean(axis=0), ' \\n std =\\n',gpr_results.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot - r2/mse/pear of 4 candidate classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['XGBoost-R','MLP-R' ,'SVM-R','GP-R']\n",
    "n_results = outter_nsplit * Ntrials\n",
    "\n",
    "r2_results_mat = np.zeros([n_results,4])\n",
    "r2_results_mat[:,0] = xgb_results['r2']\n",
    "r2_results_mat[:,1] = mlp_results['r2']\n",
    "r2_results_mat[:,2] = svr_results['r2']\n",
    "r2_results_mat[:,3] = gpr_results['r2']\n",
    "r2_results = pd.DataFrame(data=r2_results_mat,columns=labels)\n",
    "\n",
    "mse_results_mat = np.zeros([n_results,4])\n",
    "mse_results_mat[:,0] = xgb_results['mse']\n",
    "mse_results_mat[:,1] = mlp_results['mse']\n",
    "mse_results_mat[:,2] = svr_results['mse']\n",
    "mse_results_mat[:,3] = gpr_results['mse']\n",
    "mse_results = pd.DataFrame(data=mse_results_mat,columns=labels)\n",
    "\n",
    "pear_results_mat = np.zeros([n_results,4])\n",
    "pear_results_mat[:,0] = xgb_results['pear']\n",
    "pear_results_mat[:,1] = mlp_results['pear']\n",
    "pear_results_mat[:,2] = svr_results['pear']\n",
    "pear_results_mat[:,3] = gpr_results['pear']\n",
    "pear_results = pd.DataFrame(data=pear_results_mat,columns= labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append(r2_results)\n",
    "data.append(mse_results)\n",
    "data.append(pear_results)\n",
    "plotter.plot_boxplots(data=data, ylabels = [f'R\\N{SUPERSCRIPT TWO}','MSE','r'],xmin=[-0.025,0,0.6],xmax=[1.025,0.025,1.025], toSaveFig=True,title='[model_selection_reg]cqd_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rope=0.0\n",
    "to_save = True\n",
    "x_lims =  (-0.15,0.37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ( \"SVM-R\",\"XGBoost-R\")\n",
    "x=np.zeros((svr_results.shape[0],2),'float')\n",
    "x[:,1]=xgb_results['r2']\n",
    "x[:,0]=svr_results['r2']\n",
    "title = names[1]+' vs ' +names[0]+' on CQD dataset'\n",
    "left, within, right = plotter.plot_ttest(x, rope=rope,runs=Ntrials,verbose=True,names=names,title=title,toSaveFig=to_save, x_lims = x_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ( \"GP-R\",\"XGBoost-R\")\n",
    "x=np.zeros((gpr_results.shape[0],2),'float')\n",
    "x[:,1]=xgb_results['r2']\n",
    "x[:,0]=gpr_results['r2']\n",
    "title = names[1]+' vs ' +names[0]+' on CQD dataset'\n",
    "left, within, right = plotter.plot_ttest(x, rope=rope,runs=Ntrials,verbose=True,names=names,title=title,toSaveFig=to_save, x_lims = x_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ( \"MLP-R\",\"XGBoost-R\")\n",
    "x=np.zeros((mlp_results.shape[0],2),'float')\n",
    "x[:,1]=xgb_results['r2']\n",
    "x[:,0]=mlp_results['r2']\n",
    "title = names[1]+' vs ' +names[0]+' on CQD dataset'\n",
    "left, within, right = plotter.plot_ttest(x, rope=rope,runs=Ntrials,verbose=True,names=names,title=title,toSaveFig=to_save, x_lims = x_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
